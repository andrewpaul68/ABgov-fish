---
title: "Estimating power to detect trends"
author: "Carl Schwarz"
date: "4/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(lmerTest)
library(plyr)

set.seed(234234)
```

# Estimating power and sample size to detect trends in CPUE

Often, it is of interest to know:

> How many years of sampling and how many sites need to be sampled in a watershed to detect a 50%
> increase in CPUE over 10 years?

This is known as a power analysis or a sample size analysis. This document assumes that the 
general concepts of a power analysis are known and will not go into great detail about these.
Briefly, the power of a study is the probability that an effect of a certain magnitude (e.g., a 50% increase
in CPUE over 10 years) is detected given the sample size (i.e., number of sites sampled each year and
the number of years of sampling). Power is often computed using $\alpha=0.05$ with a target power
of at least 80% to detect the effect of interest.

## Sources of variation
There are many sources of variation in the data when looking at trends, two of which have a direct impact on 
the ability to detect trends (the power). Consider a study where a wateshed is repeatedly measured over
time with the same sites being measured each year. There are three levels of variation in this study:

* site-to-site variation. Some sites generally have higher densities than other sites and so the CPUE
will tend to be consistently above/below the average CPUE whenever this site is measured.

* year-to-variation. Year-specific effects (also known as process effects) may push all the CPUE readings
higher or lower in a particular year. For example, suppose that water temperature affects the CPUE with warmer
water temperatures generally having higher CPUEs. Then in warm years, all sites will tend to have warmer
water and so all sites will tend to have higher CPUEs compared to colder years.

* residual or random variation. If the exact same site was resurvyed, you will not get exactly the same
CPUE despite your best efforts. This random variation could be due to site-year local effects such as
the operator, the outside temperature when the sample was taken etc.

The latter two sources of variation (year-to-year variation (a.k.a. process variation) measured by the PROCESS standard deviation) and the within site-year
variation (meqsured by the SAMPLING standard deviation), along with the number of sites sampled each year, and the number of years
of sampling are the determinants of the power to detect a trend line.

## Why is the process standard deviation important?
Whenever fitting trends over time, you need to be concerned about 
the year-specific effects (also known as process effects). Often, a naive analysis will ignore
the process effects when fitting a trend over time which leads to erroneous inference.

In particular, year-specific effects (process effects) force the CPUE values in year 
to be higher or lower en masse, which is a violation of the key assumption of a regression analysis. 
For example, regression analysis assumes that the data in each year are always centered about the regression line as shown 
below:

```{r noprocess, echo=FALSE, fig.height=4, fig.width=6}
SD.Process <- 0
SD.Sampling <- .3
beta0 <- .20
beta1 <- .02
ylim.limits<- c(-1.5,1.5)

plotdata <- data.frame(Year=rep(2006:2011, each=10))
process.error <- rep( rnorm( length(unique(plotdata$Year)), sd=SD.Process), each=10)
sampling.error<- rnorm(nrow(plotdata), sd=SD.Sampling)
plotdata$logCPUE <- beta0 + beta1*(plotdata$Year-min(plotdata$Year))+sampling.error + process.error

yearly.means <- plyr::ddply(plotdata, "Year", plyr::summarize, logCPUE.mean = mean(logCPUE))

plot1 <- ggplot2::ggplot(data=plotdata, aes(x=Year, y=logCPUE))+
  ggtitle("Figure 1: Trend with NO process effects")+
  ylab("log(CPUE)")+xlab("Year\nPoints jittered to prevent overplotting\nRed X indicates yearly raw mean")+
  geom_point( position=position_jitter(w=0.1))+ylim(ylim.limits)+
  geom_abline(intercept=beta0-min(plotdata$Year)*beta1, slope=beta1)+
  geom_point(data=yearly.means, aes(y=logCPUE.mean), shape="X", color="red", size=4)
plot1

```

In the absence of process error, the yearly raw means will be close to the trend line because
the data in each year is centered about the trend. 

However, when process standard deviation is large, the points in each year will tend to be higher
or lower in years with positive or negative year-specific effects as illustrated below:

```{r process, echo=FALSE, fig.height=4, fig.width=6}
SD.Process <- .3


plotdata.PE <- data.frame(Year=rep(2006:2011, each=10))
process.error <- rep( rnorm( length(unique(plotdata.PE$Year)), sd=SD.Process), each=10)
sampling.error<- rnorm(nrow(plotdata.PE), sd=SD.Sampling)
plotdata.PE$logCPUE <- beta0 + beta1*(plotdata.PE$Year-min(plotdata.PE$Year))+sampling.error + process.error

yearly.means.PE <- plyr::ddply(plotdata.PE, "Year", plyr::summarize, logCPUE.mean = mean(logCPUE))

plot2 <- ggplot2::ggplot(data=plotdata.PE, aes(x=Year, y=logCPUE))+
  ggtitle("Figure 2: Trend with large process effects")+
  ylab("log(CPUE)")+xlab("Year\nPoints jittered to prevent overplotting\nRed X indicates yearly raw mean")+
  geom_point( position=position_jitter(w=0.1))+ylim(ylim.limits)+
  geom_abline(intercept=beta0-min(plotdata$Year)*beta1, slope=beta1)+
  geom_point(data=yearly.means.PE, aes(y=logCPUE.mean), shape="X", color="red", size=4)
plot2

```

Now the yearly means may be far fromo the trend line and reflect the influence of the
year-specific effects (the process effects).

Here the variation of the yearly means about the trend line represents the process standard deviation
and the variation of the inidividual points about the yearly mean represents the sampling standard deviation.

In my experience, year-specific effects can often be quite large and, in some circumstances,
be larger than sampling effects, i.e. the process standard deviation is larger than the
sampling standard deviation.

As an illustration of the impact of process error, consider Figure 3.

```{r processtrend, fig.height=6, fig.width=6, echo=FALSE}
# Create a plot illustrating the impact of process error

set.seed(124324)
library(ggplot2)
library(plyr)

SD.sampling <- .1
SD.process  <- .2


Yintercept <- -2
Slope= .05

plotdata1 <- data.frame(Scenario="NO process effects", Year=1:10, logit.psi.mean=Yintercept+ Slope*(1:10),stringsAsFactors=FALSE)
plotdata1$logit.psi.obs <- plotdata1$logit.psi.mean + rnorm(nrow(plotdata1), sd=SD.sampling)
plotdata1$logit.psi.lcl <- plotdata1$logit.psi.obs - 2*SD.sampling
plotdata1$logit.psi.ucl <- plotdata1$logit.psi.obs + 2*SD.sampling
#plotdata1


plotdata2 <- data.frame(Scenario="WITH process effects", Year=1:10, logit.psi.mean=Yintercept+ Slope*(1:10),stringsAsFactors=FALSE)
plotdata2$logit.psi.obs <- plotdata2$logit.psi.mean + rnorm(nrow(plotdata2), sd=SD.sampling)+rnorm(nrow(plotdata2), sd=SD.process)
plotdata2$logit.psi.lcl <- plotdata2$logit.psi.obs - 2*SD.sampling
plotdata2$logit.psi.ucl <- plotdata2$logit.psi.obs + 2*SD.sampling
#plotdata2



plotdata <- rbind(plotdata1, plotdata2)

avg.psi <- plyr::ddply(plotdata, "Scenario", plyr::summarize, mean.psi =mean(logit.psi.obs) )
plotdata <- merge(plotdata, avg.psi)

#plotdata

plot1 <- ggplot( data=plotdata, aes(x=Year, y=logit.psi.obs))+
   ggtitle("Figure 3: Illustration of impacts of process effects")+
   geom_point()+
   scale_x_continuous(breaks=1:10)+
   geom_errorbar( aes(ymin=logit.psi.lcl, ymax=logit.psi.ucl), width=0.1)+
   geom_abline(intercept=Yintercept, slope=Slope, linetype=2)+
   geom_line( aes(y=mean.psi))+
   geom_smooth( method='lm')+
   facet_wrap(~Scenario, ncol=1)+
   ylab('log(CPUE)')
plot1
```

In the top panel of Figure 3, there are no year-specific effects (no process effects) and the response changes over time based on the underlying trend line shown as a dashed line. Only sampling variation is present so 95% of the confidence intervals for the
mean response in a year  will overlap with the underlying trend line. 
The fitted line will be close to the true underlying trend line (solid line). 
The uncertainty is small about the overall trend (the shaded region), 
and there is clear evidence that the trend is different from a 0 trend (which is shown by the horizontal line). 

In the bottom panel of Figure 3, the year-specific effects (process effects) add extra variation to the underlying response each year due to effects such as weather, food etc. Now, the 95% confidence intervals for mean response still provide valid estimates for the yearly mean response values, but now may not overlap the true underling trend (in dashed). The fitted line will still be unbiased for the true trend (solid line), but the extra variation makes the uncertainty in the fitted line (the shaded region) 
much larger and now there is no evidence that the trend line differs from 0.

If there is substantial year-specific effects (process effects), then sampling more sites in a year will NOT be helpful. Sampling more sites in a year will shrink the size of the confidence intervals for each year in the bottom panel of Figure 3, 
but has NO impact on the process effect and so the uncertainty about the fitted line will only be reduced slightly. In cases of substantial process effects, the limiting factor for detecting trends is likely to be the total years of sampling and not the number of sites/year that are sampled.

## Why did we fit the regression line on the (natural) logarithmic scale?

Because we are interested in proportional changes (e.g. a 50% increase over 5 years), a linear mixed model
is fit on the (natural) logarithmic scale. For example, suppose that a (mixed model) regression line was fit on the 
(natural) logarithmic scale and the fitted line had the form $\log(CPUE) = 0.3 + 0.02(Year)$. This implies that 
the $\log(CPUE)_{t+1} - \log(CPUE)_{t} = 0.02$ because a slope of $0.02$ implies that the mean value of $\log(CPUE)$ changes by $0.02$ for each additional year in the study. This can be reexpressed as:
$$\log( \frac{CPUE_{t+1}}{CPUE_{t}} )= 0.02$$
or 
$$\frac{CPUE_{t+1}}{CPUE_{t}} = \exp(0.02)=1.02$$
or a 2% increase per year in the CPUE.

Because the data was fit on the (natural) logarithmic scale, the process and sampling standard deviations have 
a simple interpretation. For example, if the sampling standard deviation was 0.3, then the standard deviation of the 
original CPUE is approximatately 30% of the mean, i.e. the sampling standard deviation on the (natural) logarithmic scale
is an estimate of the coefficient of variation on the original scale.

The logarithm of the CPUE is not defined if the CPUE = 0. The usual convention is to add 1/2 of the smallest
postive values of CPUE before taking the logarithm. For example, if the smallest positive CPUE for a system was 0.32,
then $0.16 = 0.5 \times 0.32$ would be added to all of the CPUE values before taking the (natural) logarithm and fitting
the trend line.

## How to fit a trend line when process effects are present.
If process effects are ignored in the fitting process, then estimates are still unbiased, but
the reported standard error are too small (so the reported uncertainty in the slope is too small),
reported confidence intervals are too narrow, and the reported $p$-value is too small (leading
to too many false positive results where you believe you have detected a trend, when in fact, there
is no evidence of a trend).

For example, consider the data from Figure 2 where a new site is measured every year.
A naive trend line was fit using the *lm()* function:

```{r naivefit}
naive.fit <- lm(logCPUE ~ Year, data=plotdata.PE)
summary(naive.fit)$coefficients
```

Here the (naive) fitted line has a slope of `r round(coef(naive.fit)[2],2)` (SE `r round(sqrt(diag(vcov(naive.fit)))[2],2) `)
and a 95% confidence interval for the slope between `r round(confint(naive.fit)[2,1],2)` and `r round(confint(naive.fit)[2,2],2)`.
The reported $p$-value is  small ($p=$ `r format(round(summary(naive.fit)$coefficients[2,4],3),nsmall=3)`) and so you would believe that you detected an effect.


There are two ways to properly fit a trend line in the presence of process effects. Both methods are exactly equivalent
if the design is balanced (i.e. the same number of observations taken each year). 

In the first method, the trend line is fit to the AVERAGE yearly values. So the data in Figure 2 is reduced to one number
per year for a total of 6 values (6 years of data) and the trend line is fit to the averages. The averaging process can
be done using the *ddply()* function from the  *plyr* package:

```{r averageyears}
yearly.means.PE <- plyr::ddply(plotdata.PE, "Year", plyr::summarize, logCPUE.mean = mean(logCPUE))
yearly.means.PE
```
and then a regression fit is done on the means:
```{r avgfit}
avg.fit <- lm(logCPUE.mean ~ Year, data=yearly.means.PE)
summary(avg.fit)$coefficients
```

Here the slope of the fitted line on the averages has a value of `r round(coef(avg.fit)[2],2)` (SE `r round(sqrt(diag(vcov(avg.fit)))[2],2) `)
and a 95% confidence interval for the slope between `r round(confint(avg.fit)[2,1],2)` and `r round(confint(avg.fit)[2,2],2)`.
The estimated slope is the same as in the naive fit, but the (correct) reported standard error is much larger.
The reported $p$-value from the fit on the average ($p=$ `r format(round(summary(avg.fit)$coefficients[2,4],3),nsmall=3)`) is quite
large and there is no evidence of a trend, contrary to the conclusions from the naive fit.

In the second method of dealing with process effects, a mixed linear model is fit where a 
factor term (*YearC* below) represents the year-specific (process) effects:
```{r mixedfit}
plotdata.PE$YearC <- factor(plotdata.PE$Year)
mixed.fit <- lmerTest::lmer(logCPUE ~ Year + (1|YearC), data=plotdata.PE)
summary(mixed.fit)$coefficients
```
The (correct) estimated slope, its SE, and $p$ value are identical to the respective terms
from the fit on the averages because the design was balanced. If the design were not balanced, 
e.g. unequal numbers of observations in each year, the fit on the averages will only be approximate
and may differ (usually slightly) from the results of the mixed model. 

## Estimating the process and sampling standard deviations.

A key advantage of the using the second (mixed linear model) method is that estimates of the
process and sampling standard deviation can be extracted which are then used in a power/sample
size analysis. This is done using:
```{r varcor}
vc <- data.frame(VarCorr(mixed.fit))
vc[,c("grp","sdcor")]
```
In this case the estimated sampling standard deviaiton (on the logarithmic scale) is `r round(vc[vc$grp=='Residual',"sdcor"],2)`
and the estimated process standard deviation (on the logarithmic scale) is `r round(vc[vc$grp=='YearC',"sdcor"],2)`. 
Because the analysis was done on the (natural) logarithmic scale, these have a simple interpretation as the 
coefficient of variation for the individual measurements and the yearly means respectively.

## Extracting necessary information for a power analysis

In order to estimate the sampling and process standard deviation. at least two (and preferable 3+) years of data
should be available which record the site name, the year, and the CPUE at that site in that year. This information is
currently stored in a standard format for entry to FWIS -- it should either be extracted from FWIS or read from
spreadsheet with the information. I have developed an *R* function that extracts the information from the FWIS spreadsheets, 
estimates that CPUE (fish captured per 100 m or fish capture per 100 s) for each species of interest.

There are three cases to consider

1. **Single year of data.** In this case, only an estimate of the sampling standard deviation is possible. 
The process standard deviation cannot be estimated because process standard deviation operates on the
year-to-year level and there are no replicate years. The sampling standard deviation is simply the
standard deviation of the (natural) logarithm of the CPUE.

2. **Two years of data.** In this case, it is assumed that there was NO trend over the two years. If new sites
were measured in each year, then it is impossible to separate the site-to-site standard deviation and the
sampling standard deviation.  The mixed linear model does not have trend term, and is
$$\log(CPUE) \sim  (1|YearC)$$
where *YearC* is an *R* factor variable for the year of the study.    
If some of the sites are measured in both years, then the above model is modified to capture
the site-to-site variation:
$$\log(CPUE) \sim (1|Year)+ (1|SiteF)$$
where *SiteF* is an *R* factor variable for the sites.

3. **Three or more years of data**. In this case, a trend is fit to the data to remove its effect before finding
the variance components. The mixed linear model when new sites are measured each year is:
$$\log(CPUE) \sim Year + (1|YearC)$$
The mixed linear model when some sites are measured in more than one year is
$$\log(CPUE) \sim Year + (1|YearC) + (1|SiteF)$$

In the second and third cases, the variance components can be extracted after the fit using the
methods presented earlier.

As will be seen later, the process standard deviaton is often the limiting factor in
determing the power to detect a trend. Some of the process effects may be attributable
to other variables that also vary at the yearly level such as stream temperature, conductivity, etc.
The additional covariates can be added to the models for cases 2 and 3 above to try and reduce
the size of the process standard deviation.

## (Finally) estimating the power and sample size
Once the sampling and process standard deviatons (after the analysis of the CPUE on the logarithmic scale) are 
available, we can now examine how the power to detect effects varies by the size of the effect (the trend),
the number of sites sampled per year, and the number of years of sampling (and the pattern of sampling years).

We first translate the desired change over xx years into the yearly proportional change (the trend to be detected).
For example, if we wish to detect a 50% increase over 5 years, this implies that 
$$CPUE_{Year~5}=1.50 \times CPUE_{Year~1}$$
or 
$$\frac{CPUE_{Year~5}}{CPUE_{Year~1}} = 1.50 = (1+r)^{5-1} = (1+r)^4$$
where $r$ is the proportional change per year. Notice that the exponent of $(1+r)$ is one less than the number of years because the first years establishes the baseline value.

We can solve the above equation to find that $r =$ `r round(1.50^0.25,2)`, 
i.e. corresponding to a `r 100*(round(1.50^0.25-1,2))`% increase per year (compounded). For example, suppose that
the mean CPUE had the value of 10 in year 1. Then in year 2, the mean CPUE will be $10 \times$ `r round(1.50^0.25,2)` or
`r round(10*(1.50^0.25)^1,2)`. Then in year 3, the mean CPUE will be `r round(10*(1.50^0.25)^1,2)` $\times$ `r round(1.50^0.25,2)`
or `r round(10*(1.50^0.25)^2,2)`. By year 5, the mean CPUE will have increased by 50% to 15.

We can create the following table showing the trend (on the logarithmic scale) needed for certain sized trends.
<style type="text/css">.table {  width: 40%;}</style>
: Table 1. Slope on the (natural) logarithmic scale corresponding to certain change over a certain period.

|  Change  | Over 5 Years | Over 10 Years |
|---------:|-------------:|--------------:|
|  10%     |`r format(round(1.10^0.25-1,3),3)` | `r sprintf('%6.3f',1.10^(1/9)-1,3)`  |
|  30%     |`r format(round(1.30^0.25-1,3),3)` | `r sprintf('%6.3f',1.30^(1/9)-1,3)`  |
|  50%     |`r format(round(1.50^0.25-1,3),3)` | `r sprintf('%6.3f',1.50^(1/9)-1,3)`  |
| 100%     |`r format(round(2.00^0.25-1,3),3)` | `r sprintf('%6.3f',2.00^(1/9)-1,3)`  |
| 200%     |`r format(round(3.00^0.25-1,3),3)` | `r sprintf('%6.3f',3.00^(1/9)-1,3)`  |


I have written a *R* function (*slr.power.stroup()*) that estimates the power to detect a specified
trend, given the process and sampling standard deviations, the $\alpha$ level (traditionally 0.05) and 
the sample sizes (number of sites measured each year and the number of years and pattern of sampling across years). 
This uses a methods developed by Stroup (1999). This function has arguments for the trend to be detected,
the two standard deviations, the $\alpha$ level, and an argument that captures both the number of sites sampled each year,
the number of years of sampling, and the pattern of the yearly samples (the *Xvalues* argument). 
For example, suppose that four sites are to be sampled in each of 5 years. Then the *Xvalues* argument
would be specified as
$$Xvalues=c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5)$$
The individual values refer to the years sampled, and the replicated values specify how many sites
are sampled each year. It is not necessary to worry if the same sites are sampled each year or new sites
are sampled each year because any site-to-site variation will have been accounted for when the model
was fit to the $\log(CPUE)$ data to estimate the variance components.

This can be specified in short hand way in *R* using
$$Xvalues=rep(1:5, each=4)$$

Similarly, if sampling is only done in years 1, 3, and 5 with four sites sampled in each year, 
then the *Xvalues* argument is specificed as:
$$Xvalues=c(1,1,1,1,3,3,3,3,5,5,5,5)$$
This provides much flexibility to examine the impacts of different sampling effort and patterns on the power.

This function can be repeated called with different combinations of effort and trend and the results plotted
as shown below.
```{r powerexample,fig.height=6,fig.width=6 }
source('functions.R')
  vc <- data.frame(SD.sampling=.8, SD.process=0.1, Watershed="Example ", Measure="CPUE_100m")
  alpha=0.05
  scenarios <- expand.grid(PerChange=c(10, 30, 50, 100, 200),
                           Years=c(5,10),
                           Sampling.SD=vc$SD.sampling,
                           Process.SD=vc$SD.process,
                           sites.per.year=seq(20,100,10),
                           Watershed=vc$Watershed,
                           Measure=vc$Measure,
                           alpha=alpha)
  scenarios$Scenario <- 1:nrow(scenarios)
  # estimate the power to detect a trend for each scenario
  power <- plyr::ddply(scenarios, "Scenario", function(x){
      # estimate compounded trend line on the log scale
      Trend <-  (x$PerChange/100+1)^(1/(x$Years-1))-1
      # sampling every year
      Xvalues <- rep(1:x$Year, each=x$sites.per.year)
      res <- slr.power.stroup(Trend=Trend, 
                              Xvalues    =Xvalues   , 
                              Process.SD =x$Process.SD, 
                              Sampling.SD=x$Sampling.SD, 
                              alpha      =x$alpha)
      res <- cbind(res, x)
      res
   })
   # make a plot
   #browser()
   plotdata <- power
   plotdata$Years2 <- paste("Over ", plotdata$Year," Years",sep="")
   plotdata$PerChangeF <- factor(plotdata$PerChange)
   power.plot <- ggplot2::ggplot(data=plotdata, aes(x=sites.per.year, y=power.1sided.a, color=PerChangeF))+
      ggtitle(paste("Power to detect changes over time for \n", vc$Watershed, " ",vc$Type,"  ", vc$Measure,"\n alpha=",power$alpha[1],
                    "; Process SD= ", format(round(power$Process.SD[1] ,2),nsmall=2), 
                    "; Sampling SD= ",format(round(power$Sampling.SD[1],2),nsmall=2), sep=""))+
      geom_line(aes(group=PerChangeF, linetype=PerChangeF))+
      ylab("Power")+ylim(0,1)+geom_hline(yintercept=0.80)+
      facet_wrap(~Years2, ncol=1, scales='fixed')+
      scale_color_discrete(name="Percent\nChange")+
      scale_linetype_discrete(name="Percent\nChange")
   plot(power.plot)
```
```{r  samplesize}
# Find the sample size per year to detect 100% change over 5 years with 80% power
temp <- power[ power$Years==5 & power$PerChange==100,]
select <- which.max( temp$power.1sided.a >= 0.80)
ss <- temp[select, "sites.per.year"]
```

From this figure, we see that approximately `r ss` sites per year would be required to 
have a power of about 80% to detect a 
100% increase over 5 years when the process standard deviation was `r temp[select,"Process.SD"]`, the
sampling standard deviaton was `r temp[select,"Sampling.SD"]` at $\alpha =$ `r temp[select, 'alpha']`.

The power is relatively insensitive to the number of sites once it becomes large enough that
the uncertainty in each year's mean CPUE is small so that process effects dominate changes
from year to year.

## Using the sample template.
I have created a sample template to help estimate the power sample size for each system.
Here are the steps to be taken to analyze a set of data for a system

1. Create a directory for the Excel workbooks that contain the data over a number of years.
These workbooks need to be in the standard FWIS format with a worksheet called *Electrofishing*
that records the results for both measured and counted fish.

2. Copy the template trend file (*power.trend.template.R*) and the file that contains
the functions to read the FWIS file and do the power analysis (*functions.R*) to the directory from above. 
You will make several modifications
to this template file. Start by renaming the *power.trend.template.R* to include the watershed name, e.g.
similar to *power.trend.nordegg.R*.

3. Specify the name of the watershed. This is, surprisingly, not readily available from the FWIS
workbook and is specified similar to:
```{r FWISworkbook,eval=FALSE}
WatershedName <- "Nordegg"
```

4. Specify the codes for the species of interest for this analysis and the equipment types
to be selected from the FWIS sheet. The FWIS sheets record all species detected, but these
may not be all of interest.
If all species are
to be analyzed, specify *'ALL'* in the list of species names as shown in the commented *R* line below
```{r FWISworkbook10,eval=FALSE}
target.species <- c("BKTR","BLTR","MNWH")
#target.species <- "ALL"  # use if all species are of interest

# equipment type
select.equipment = "Backpack"  # Valid values are Backpack or Float
```

5. Modify the template file with the names of the FWIS workbooks. This section of code will look similar to:
```{r FWISworkbook30,eval=FALSE}
FWIS.files.csv<- textConnection("
workbookName, sheetName
FWMIS Loadform BLTR 2015 Nordegg and Tribs-fake.xls,     Electrofishing
FWMIS Loadform BLTR 2016 Nordegg and Tribs.xls,          Electrofishing")
```
In the *Nordegg* example, only one year of data was present (2016), so I generated a fake dataset for the 2015 data.

6. If the Excel workbooks are not in the standard FWIS format, you will need to modify 
the *functions.R* file and the *read.FWIS.workbook()* function. In the *Nordegg* example, the
workbooks are in the standard FWIS format, so no modifications were needed. In the *Red Deer* example,
the workbooks are not in the standard FWIS format, so the *read.FWIS.workbook()* function was modified.  
The *read.FWIS.workbook()* function also has arguments to use both the counted and measured fish, or
to select which equipment to use (backpack, floatboats, etc.). Consult the documentation in the
function for more details.

7. Run through the code stopping now and then to check for errors and if there are outliers. Typical check
points are:

7.1 Checking that you have spelled the FWIS file names correctly:
```{r checkfiles,eval=FALSE}
# Check that all FWIS files exist
plyr::d_ply(FWIS.files, "workbookName", function (x){
  if(!file.exists(x$workbookName))stop(paste("File ",x,' not found '))
})
```

7.2 Checking that the site names are spelled consistently, etc
```{r checksites, eval=FALSE}
# After reading in the data, you should check  basic statistics such as the years
# measurements are taken, the Location names are spelled consistently, etc

xtabs(~Location..+Year,      data=cpue , exclude=NULL, na.action=na.pass)
xtabs(~Species.Code + Year,  data=cpue , exclude=NULL, na.action=na.pass)
xtabs(~data.type + Year,     data=cpue , exclude=NULL, na.action=na.pass)
xtabs(~equip.type + Year,    data=cpue , exclude=NULL, na.action=na.pass)

xtabs(~interaction(Watershed,Type,Measure, drop=TRUE)+Year, data=cpue, exclude=NULL, na.action=na.pass)
```

7.3 Check for and removing any outliers spotted on the preliminary plots. In this example, 
outliers were spotted on the *FloatBoat* samples in 2005 and were removed.
```{r checkoutliers,eval=FALSE}
outliers <- cpue$Type=="FloatBoat" & cpue$Measure=="BLTR_km"  & (cpue$value > 2)  |
            cpue$Type=="FloatBoat" & cpue$Measure=="BLTR_km"  & (cpue$Year > 2005)
cpue[outliers,]

cpue <- cpue[ !outliers,]
```

7.4 Estimate the variance components. If only one year of data is present, then it is not possible to estimate the
process standard deviation and this will have to be manually added using typical values from other watersheds.

```{r estvarcomp, eval=FALSE}

# fit the model to the log to get the sampling and process error relative to the mean
vc <-  plyr::ddply(cpue, c("Watershed","Measure","Type"), estimate.var.comp)
cat("Estimated variance components\n")
vc

# you need to manually change SD.process if there is only 1 year of sampling
# or if they cannot be estimated.
# At the moment, I just delete then
vc <- vc[ !(is.na(vc$SD.sampling) | is.na(vc$SD.process)),]
vc
```
Sometimes, the mixed linear model fails -- the variance components will be set to missing values and a
message will appear in the list of variance components. The causes of these failures are difficult to predict,
but often caused by singularities in the data (e.g. all the CPUE are identically equal to 0!). Please contact me
for help in resolving the cases where the variance component analysis fails.


7.5 Finally, perform the power/sample size analysis:

```{r power, eval=FALSE}
power.res <- ddply(vc, c("Watershed","Type","Measure"), estimate.power)
```
This will automatically create the plots in the current working directory. The
*power.res* data frame is also available for custom analysis or plotting.
